{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f48da4-f88a-47c6-986d-b25b4177d24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:30:44.355078Z",
     "iopub.status.busy": "2025-06-20T20:30:44.354763Z",
     "iopub.status.idle": "2025-06-20T20:31:51.041253Z",
     "shell.execute_reply": "2025-06-20T20:31:51.040756Z",
     "shell.execute_reply.started": "2025-06-20T20:30:44.355054Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide the aws_access_key_id ASIAVFNG7CO7KKWE2YWT\n",
      "Provide the aws_secret_access_key pHOS5bomDVWl7ve15+S51YdBnIViLqu3meQMd4hA\n",
      "aws_session_token IQoJb3JpZ2luX2VjEN3//////////wEaCXVzLXdlc3QtMiJHMEUCIQCuI+tAJnEmup7jX+xevdj57BAIH8xqDeSALCg97iONXQIgNuZ+O4OAOU0iKT0O1oHv+Ja86HKNmsW+u0KPtKSPLgUqmgMIxv//////////ARAFGgwzNTUyMjE4MzY3MzQiDNC+6YYmXvK7CZdP8yruAmU0sYqGvLi75bjKSPgJgXhHUHAGhQoA7K+o9IVSydIlJMxJYc/uZlUspQaC8g9qXs34djHOz1Si0IoTy6Dzxp6cdSNWPSGiwrAhvEklyaZlRVBcgtVQhb75stUYF400giRsTt9GurZlQzX1tQ//tDxVdGAArHAx4gPD6negxU1roSVuimimXrCzOGUak1wtNpXaNyv7GjnjuhdHfeDOzBZegnF+LOHl7Awmtn8cgnFESPF/F6FjltcmojoMTHVWotP5vS3avCwKy/fcdj+S80Xu5GkiSs5srgs173kdQ3FA9/aiDFPknFHu+s3MgOQdtXJI2l7VIHIKao+zVGzqK/lPUW1+pEYkSNR+KKHZ/0BlYma2M5SVN2iWwHip+P/jEEzo4LupZqzPvGCQRX1bE2htDtz93w5MvILtzHIC929VrqBkl8bx87esb9gyNgKAcm85N3BeJAeMwLMsiLH5nuU1V3RT8U3Ga40KgGGPdzCJitfCBjqmAdVu5rfmePH6Y/kf4LCShxH3owAxfC/BdS5ox9ar9640p5xUX2FRXS57N3z0rl0Qsj8OReg7RqZ4DhokpskDfrf3S/7d1hSwbdJjM1ft0q301UzL39gDtCz2VX2ojLgEccjH1CNStti6bUFDk2mE3wVAkDX4ZoBzc1U7aOd+0rPePAyhk1mgcAp8WlqJ8DrsGQl4oqn0vDk7rWbFACjMpnm/dxuva4Y=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision-sciences-bk2/PCL_chargeoff_report_20241031.dat\n",
      "decision-sciences-bk2/PCL_chargeoff_report_20241231.dat\n",
      "decision-sciences-bk2/PCL_masterline_cycle_perf_summary_20241031.dat\n",
      "decision-sciences-bk2/PCL_masterline_cycle_perf_summary_20241231.dat\n",
      "decision-sciences-bk2/PCL_masterline_monthly_perf_summary_20241031.dat\n",
      "decision-sciences-bk2/PCL_masterline_monthly_perf_summary_20241231.dat\n",
      "decision-sciences-bk2/PCL_perf_flag_20241031.dat\n",
      "decision-sciences-bk2/PCL_perf_flag_20241231.dat\n",
      "decision-sciences-bk2/PCL_subline_perf_20241031.dat\n",
      "decision-sciences-bk2/PCL_subline_perf_20241231.dat\n",
      "decision-sciences-bk2/PL_chargeoff_report_20241231.dat\n",
      "decision-sciences-bk2/PL_payment_file_20241231.dat\n",
      "decision-sciences-bk2/PL_perf_flag_20241231.dat\n",
      "decision-sciences-bk2/bk2_oot_12_df_v2.dat\n",
      "decision-sciences-bk2/bk2_oot_df_12.dat\n",
      "decision-sciences-bk2/bk2_oot_df_v2.dat\n",
      "decision-sciences-bk2/bk2_test_df.dat\n",
      "decision-sciences-bk2/bk2_test_df_v2.dat\n",
      "decision-sciences-bk2/bk2_testing_100K_sample_for_ck.zip\n",
      "decision-sciences-bk2/bk2_testing_10K_sample_for_ck.zip\n",
      "decision-sciences-bk2/bk2_testing_1K_sample_for_ck.zip\n",
      "decision-sciences-bk2/bk2_train_df.dat\n",
      "decision-sciences-bk2/bk2_train_df_sample.dat\n",
      "decision-sciences-bk2/bk2_train_df_v2.dat\n",
      "decision-sciences-bk2/dev_perf_df.dat\n",
      "decision-sciences-bk2/pl_perf_df_2024_10.dat\n",
      "  272118501 / 272118501  (100.00%)"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "class Upload_ProgressPercentage(object):\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._size = float(os.path.getsize(filename))\n",
    "        self._seen_so_far = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def __call__(self, bytes_amount):\n",
    "\n",
    "        with self._lock:\n",
    "            self._seen_so_far += bytes_amount\n",
    "            percentage = (self._seen_so_far / self._size) * 100\n",
    "            sys.stdout.write(\"\\r  %s / %s  (%.2f%%)\" % (self._seen_so_far, self._size, percentage))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "class Download_ProgressPercentage(object):\n",
    "    def __init__(self, client, bucket, filename):\n",
    "        self._filename = filename\n",
    "        self._size = client.head_object(Bucket=bucket, Key=filename)['ContentLength']\n",
    "        self._seen_so_far = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def __call__(self, bytes_amount):\n",
    "\n",
    "        with self._lock:\n",
    "            self._seen_so_far += bytes_amount\n",
    "            percentage = (self._seen_so_far / self._size) * 100\n",
    "            sys.stdout.write(\"\\r  %s / %s  (%.2f%%)\" % (self._seen_so_far, self._size, percentage))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "\n",
    "class s3_helper:\n",
    "    def __init__(self):\n",
    "        self.session = boto3.Session(aws_access_key_id=input(\"Provide the aws_access_key_id\"),\n",
    "                                     aws_secret_access_key=input(\"Provide the aws_secret_access_key\"),\n",
    "                                     aws_session_token=input(\"aws_session_token\"),\n",
    "                                     region_name='us-west-2',)\n",
    "        self.s3 = self.session.client('s3')\n",
    "        self.bucket = 'upg-decisionsciences-data-usw2-services'\n",
    "\n",
    "    def download(self, s3_file, file_location):\n",
    "        \"\"\"\n",
    "        Download data from S3:\n",
    "        s3_file: provide the name of file including the path (don't include the bucket name)\n",
    "        file_location: provide the local path, make sure to include \"/\" at the end,\n",
    "        do not provide file name, it is the same as the one used in s3\n",
    "        \"\"\"\n",
    "        file_name = s3_file.split('/')[-1]\n",
    "        progress = Download_ProgressPercentage(self.s3, self.bucket, s3_file)\n",
    "        self.s3.download_file(self.bucket, s3_file, file_location+file_name, Callback=progress)\n",
    "\n",
    "    def upload(self, file_location, file_name, s3_location):\n",
    "        \"\"\"\n",
    "        Upload data to S3:\n",
    "        file_location: provide the local path, make sure to include \"/\" at the end\n",
    "        file_name: provide the name of the file to be uploaded\n",
    "        s3_location: Provide the S3 location, do not include bucket name or file name, make sure to include \"/\" at the end\n",
    "        \"\"\"\n",
    "        self.s3.upload_file(file_location+file_name, self.bucket, s3_location+file_name, Callback=Upload_ProgressPercentage(file_location+file_name))\n",
    "\n",
    "    def delete(self, s3_file):\n",
    "        \"\"\"\n",
    "        Delete S3 file:\n",
    "        s3_file: provide the name of the file including the path (don't include the bucket name)\n",
    "        \"\"\"\n",
    "        self.s3.delete_object(Bucket=self.bucket, Key=s3_file)\n",
    "\n",
    "    def list_files(self, s3_folder):\n",
    "        \"\"\"\n",
    "        List files in an S3 folder:\n",
    "        s3_folder: provide the full folder name (don't include the bucket name),\n",
    "        Provide empty string to list all files in the bucket\n",
    "        \"\"\"\n",
    "        for content in self.s3.list_objects(Bucket=self.bucket, Prefix=s3_folder)['Contents']:\n",
    "            print(content['Key'])\n",
    "\n",
    "    def upload_from_ram(self, df, file_name, s3_location, file_type):\n",
    "        \"\"\"\n",
    "        Upload a pandas dataframe in RAM directly to S3 and save in csv/pickle format:\n",
    "        df: pandas dataframe\n",
    "        file_name: provide the name of the file to be saved\n",
    "        s3_location: Provide the S3 location, do not include bucket name or file name, make sure to include \"/\" at the end\n",
    "        file_type: 'csv' or 'pickle'\n",
    "        \"\"\"\n",
    "        if file_type=='csv':\n",
    "            with io.StringIO() as csv_buffer:\n",
    "                df.to_csv(csv_buffer, index=False)\n",
    "                self.s3.put_object(Bucket=self.bucket, Key=s3_location+file_name, Body=csv_buffer.getvalue())\n",
    "        elif file_type=='pickle':\n",
    "            pickle_buffer = pickle.dumps(df)\n",
    "            self.s3.put_object(Bucket=self.bucket, Key=s3_location+file_name, Body=pickle_buffer)\n",
    "        else:\n",
    "            print ('This file type is not supported by the function. Please save to a local location and upload.')\n",
    "\n",
    "\n",
    "s3 = s3_helper()\n",
    "\n",
    "s3.list_files('decision-sciences-bk2/')\n",
    "\n",
    "s3.download('tu_account_files/tu_raw_account_2017.dat', 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec5ac3-8db3-41d4-ad80-c999480dcd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
